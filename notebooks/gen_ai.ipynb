{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d5f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv \n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db440a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyCLCv5xhsGK6mQqy0RAlwg1CiAMGIXqTBk\n",
      "Langchain is a framework designed to simplify the development of applications powered by large language models (LLMs). Think of it as a toolkit that helps you connect LLMs like GPT-3, Bard, or open-source models to other data sources and tools, allowing you to build more complex and useful AI applications.\n",
      "\n",
      "Here's a breakdown of what it is and what it does:\n",
      "\n",
      "**Key Concepts:**\n",
      "\n",
      "* **LLMs at the Core:** Langchain's primary focus is to make it easier to work with LLMs.  It provides abstractions and tools to interact with various LLM providers (OpenAI, Google, Cohere, etc.) in a consistent way.\n",
      "\n",
      "* **Data-Aware Applications:**  One of Langchain's strengths is its ability to connect LLMs to external data sources. This allows you to build applications that can answer questions based on your specific knowledge base, not just the general knowledge the LLM was trained on.\n",
      "\n",
      "* **Agentic Applications:**  Langchain enables the creation of \"agents\" that can use LLMs to reason about their environment, decide which actions to take, and execute those actions.  This opens the door to building autonomous systems that can perform complex tasks.\n",
      "\n",
      "**Key Components/Modules:**\n",
      "\n",
      "* **Models:**  Provides a standard interface for interacting with different LLMs and other language models (e.g., text embedding models).  This allows you to easily switch between models without changing your code.\n",
      "* **Prompts:**  Provides tools for creating and managing prompts (the input you give to the LLM).  This includes prompt templates, which allow you to dynamically generate prompts based on user input or other data.\n",
      "* **Chains:** The core building block of Langchain. Chains are sequences of calls to LLMs or other utilities.  They allow you to combine multiple steps into a single workflow.  For example, you could chain together a prompt template, an LLM, and an output parser.\n",
      "* **Indexes:**  Provides tools for indexing and retrieving data, allowing you to create a knowledge base for your LLM to draw upon.  This includes techniques like document loaders, text splitters, and vectorstores.\n",
      "* **Memory:**  Allows you to persist information between calls to the LLM.  This is essential for building conversational applications that can remember previous interactions.\n",
      "* **Agents:**  Enables the creation of agents that can use LLMs to decide which actions to take.  Agents typically have access to a set of tools (e.g., a search engine, a calculator, a database) and use the LLM to choose which tool to use based on the current situation.\n",
      "* **Callbacks:** Provides a standard way to log and monitor the execution of Langchain components. This is useful for debugging and understanding how your application is working.\n",
      "\n",
      "**Why Use Langchain?**\n",
      "\n",
      "* **Abstraction and Standardization:** Langchain provides a consistent interface for interacting with different LLMs and other tools, making it easier to switch between them and to write code that is portable.\n",
      "* **Modularity and Reusability:**  The modular design of Langchain allows you to easily combine different components to create complex applications.  You can also reuse existing components in new applications.\n",
      "* **Community Support:** Langchain has a large and active community, which means you can find plenty of help and support online.\n",
      "* **Rapid Prototyping:** Langchain makes it easier to quickly prototype and experiment with different ideas.\n",
      "* **Production-Ready:** Langchain is designed to be used in production environments.\n",
      "\n",
      "**Example Use Cases:**\n",
      "\n",
      "* **Chatbots:** Build conversational agents that can answer questions, provide customer support, or perform other tasks.\n",
      "* **Question Answering:**  Create applications that can answer questions based on a specific knowledge base (e.g., a company's internal documents).\n",
      "* **Text Summarization:**  Automatically summarize long documents or articles.\n",
      "* **Code Generation:**  Generate code from natural language descriptions.\n",
      "* **Data Extraction:**  Extract information from unstructured text.\n",
      "* **Agent-Based Automation:** Automate complex tasks by creating agents that can use LLMs to reason about their environment and take actions.\n",
      "\n",
      "**In summary, Langchain is a powerful framework that simplifies the process of building applications powered by large language models by providing abstractions, tools, and components for connecting LLMs to data sources, creating chains of operations, and building intelligent agents.**  It's a rapidly evolving project, so staying up-to-date with the latest features and best practices is important.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv()\n",
    "# GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",api_key=GOOGLE_API_KEY)\n",
    "\n",
    "response = llm.invoke(\"What is Langchain ?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b44e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928847c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'collection'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \u001b[33m'\u001b[39m\u001b[33m..\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m'\u001b[39m)))\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tool\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mml_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_predict_model  \u001b[38;5;66;03m# Adjusted import path\u001b[39;00m\n\u001b[32m     10\u001b[39m stock_price_tool = Tool(\n\u001b[32m     11\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mStockPricePredictor\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     func=\u001b[38;5;28;01mlambda\u001b[39;00m ticker: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe predicted price for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is â‚¹\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_predict_model(ticker)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33mUse this tool to predict the next stock price for a given ticker (e.g., \u001b[39m\u001b[33m'\u001b[39m\u001b[33mRELIANCE\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     14\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\All Python\\Gen AI Project\\Stock AI\\src\\ml_models\\main.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcollection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collect\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m data_preprocessing\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpreparation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preparation\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'collection'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Dynamically add the `src` directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))\n",
    "\n",
    "from langchain.tools import Tool\n",
    "from ml_models.main import run_predict_model  # Adjusted import path\n",
    "\n",
    "stock_price_tool = Tool(\n",
    "    name=\"StockPricePredictor\",\n",
    "    func=lambda ticker: f\"The predicted price for {ticker} is â‚¹{run_predict_model(ticker):.2f}\",\n",
    "    description=\"Use this tool to predict the next stock price for a given ticker (e.g., 'RELIANCE').\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0879b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tools.stock_tool import stock_price_tool\n",
    "\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key=GOOGLE_API_KEY)\n",
    "\n",
    "tools = [stock_price_tool]\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")\n",
    "\n",
    "# CLI Loop\n",
    "while True:\n",
    "    user_input = input(\"ðŸ§‘ You: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    response = agent.run(user_input)\n",
    "    print(\"ðŸ¤– Gemini:\", response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
